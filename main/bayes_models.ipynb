{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import pymorphy2\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>А попа подозревала давно,что ты с кавказа..пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speech</td>\n",
       "      <td>З прошедшим Днем Ангела))))))))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skip</td>\n",
       "      <td>Два дня до отлёта с острова!!!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Блин, почему эта жизнь столь не справедлива ((((</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skip</td>\n",
       "      <td>где еще встречать свой день рождения как не на...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  negative  А попа подозревала давно,что ты с кавказа..пер...\n",
       "1    speech                    З прошедшим Днем Ангела))))))))\n",
       "2      skip                 Два дня до отлёта с острова!!!!!!!\n",
       "3  negative   Блин, почему эта жизнь столь не справедлива ((((\n",
       "4      skip  где еще встречать свой день рождения как не на..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('rusent.csv')\n",
    "#data_2 = pd.read_csv('rusentiment_preselected_posts.csv')\n",
    "#data_1 = pd.read_csv('rusentiment_random_posts.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Избавляемся от таких классов как skip и speech\n",
    "data = data[(data.label!='skip') & (data.label != 'speech') & (data.label != 'neutral')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9764"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка текстовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('russian'))\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def text_processing(data):\n",
    "    t_arr = TweetTokenizer().tokenize(data)\n",
    "    cleaned_data = []\n",
    "    for word in t_arr:\n",
    "        if word.lower() not in stopwords:\n",
    "            if word.isalnum() and word != 'RT':\n",
    "                lemma = morph.parse(word.lower())[0].normal_form\n",
    "                cleaned_data.append(lemma)\n",
    "        else:\n",
    "            pass\n",
    "        fin_str = ' '.join(cleaned_data)\n",
    "    return fin_str\n",
    "\n",
    "def hands_re(text):\n",
    "    punctuation = string.punctuation + '\\u2014\\u2013\\u2012\\u2010\\u2212' + '«»‹›‘’“”„`'\n",
    "    word_tokenize = re.compile(r\"([^\\w_\\u2019\\u2010\\u002F-]|[+])\")\n",
    "    tokenized_words = []\n",
    "    for token in word_tokenize.split(text):\n",
    "        if token and not token.isspace() and not token in punctuation: # если слово не попадает в те которые мы исключаем\n",
    "            tokenized_words.append(token.lower())        # добавляем слово в список\n",
    "    return tokenized_words                     # возвращаем список слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "\n",
    "for text in data['text']:\n",
    "    new_text = text_processing(text)\n",
    "    clean_data.append(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Записываем фактические значения текста в X, фактические значения меток в y:\n",
    "X = clean_data\n",
    "y = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dns\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1168897, 5651030)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim \n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "        X,\n",
    "        size=20,\n",
    "        window=10,\n",
    "        min_count=2,\n",
    "        workers=10)\n",
    "model.train(X, total_examples=len(X), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, doc2vec, FastText\n",
    "w2v = KeyedVectors.load_word2vec_format('model.bin', binary=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('королева_PROPN', 0.5260607004165649),\n",
       " ('король_NOUN', 0.5213080644607544),\n",
       " ('король_PROPN', 0.46887069940567017),\n",
       " ('высочество_PROPN', 0.41855698823928833),\n",
       " ('королевский_ADJ', 0.4164617657661438),\n",
       " ('величество_PROPN', 0.41055727005004883),\n",
       " ('королева_ADV', 0.4056137800216675),\n",
       " ('принцесса_NOUN', 0.3994409441947937),\n",
       " ('герцог_NOUN', 0.3904263377189636),\n",
       " ('величество_NOUN', 0.39014965295791626)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['королева_NOUN'],negative=['женщина_NOUN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'positive', ..., 'positive', 'positive',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9764"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые классификаторы не способны справляться с нечисловыми классами, в таком случае решением является преобразовать к числовому формату.\n",
    "\n",
    "Это делается посредством класса LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classEncoder = LabelEncoder() # Создаем объект класса\n",
    "labelled_y = classEncoder.fit_transform(y) \n",
    "# Здесь LabelEncoder смотрит на весь вектор, и ставит в соответствие каждому символьному классу в соответствие число"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classEncoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u0295' in position 30552: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-db5cfa6a81cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1251.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u0295' in position 30552: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "f = open('X.txt', 'w')\n",
    "f.write('/n'.join(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive = ['ахи',\n",
    "            'крутой',\n",
    "           'прекрасный',\n",
    "           'обожать',\n",
    "           'понравиться',\n",
    "           'отличный',\n",
    "           'ура',\n",
    "           'классный',\n",
    "           'хороший',\n",
    "           'круто',\n",
    "           'шикарный',\n",
    "           'приятно',\n",
    "           'любимый',\n",
    "           'ахахахах',\n",
    "           'супер',\n",
    "           'красивый',\n",
    "           'любить',\n",
    "           'счастие',\n",
    "           'замечательный',\n",
    "           'офигенный',\n",
    "           'красиво',\n",
    "           'молодец',\n",
    "           'прикольный',\n",
    "           'нравиться',\n",
    "            'красавчик',\n",
    "           'идеальный',\n",
    "           'охуенно',\n",
    "           'еее',\n",
    "           'красавец',\n",
    "           'наслаждаться',\n",
    "           'тащиться',\n",
    "            'улыбнуться',\n",
    "           'счастливый',\n",
    "           'отлично',\n",
    "           'классно',\n",
    "           'милый',\n",
    "           'ржать',\n",
    "           'слава',\n",
    "            'чемпион',\n",
    "           'подруга',\n",
    "           'здорово',\n",
    "           'удача',\n",
    "           'чудесный',\n",
    "           'влюбиться',\n",
    "           'родной',\n",
    "            'гордиться',\n",
    "           'трек',\n",
    "           'правда',\n",
    "           'красота',\n",
    "           'довольный',\n",
    "           'танцевать']\n",
    "negative = ['скучно',\n",
    "           'пиздец',\n",
    "           'говно', \n",
    "           'ненавидеть', \n",
    "           'жалко',\n",
    "            'заболеть',\n",
    "           'грустно',\n",
    "           'блять', \n",
    "           'умереть', \n",
    "           'лох',\n",
    "            'болеть',\n",
    "           'жаль',\n",
    "           'плохо', \n",
    "           'послать', \n",
    "           'убивать',\n",
    "            'надоесть',\n",
    "           'ужасный',\n",
    "           'бред', \n",
    "           'обидный', \n",
    "           'ппц',\n",
    "            'достать',\n",
    "           'ужас',\n",
    "           'хватить', \n",
    "           'хреновый', \n",
    "           'дура',\n",
    "            'тормоз',\n",
    "           'тупой',\n",
    "           'смерть', \n",
    "           'скорбеть',\n",
    "            'дебил',\n",
    "           'идиот',\n",
    "           'хер', \n",
    "           'подонок', \n",
    "           'хулить',\n",
    "            'одиночество',\n",
    "           'кошмар',\n",
    "           'забыть', \n",
    "           'бедный', \n",
    "           'нахрен',\n",
    "            'олень',\n",
    "           'докатиться',\n",
    "           'тварь', \n",
    "           'больно', \n",
    "           'печаль',\n",
    "            'бесить',\n",
    "           'зло',\n",
    "           'брр', \n",
    "           'грустить', \n",
    "           'мудак']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_distributions = []\n",
    "words = []\n",
    "positive_dict = {}\n",
    "for word in positive:\n",
    "#word = 'танцевать'\n",
    "    for text in X:\n",
    "        stroka = text.split(' ')\n",
    "        for ind, token in enumerate(stroka):\n",
    "        #print(token)\n",
    "            if word == token:\n",
    "                if token != stroka[-1]:\n",
    "                    words.append(stroka[ind+1])\n",
    "    \n",
    "    counts = Counter(words)\n",
    "    positive_dict[word] = counts.most_common(1000)\n",
    "    words = []\n",
    "#print(positive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_distributions = []\n",
    "words = []\n",
    "negative_dict = {}\n",
    "special_texts = []\n",
    "for word in negative:\n",
    "        #print(word)\n",
    "        for text in X:\n",
    "            stroka = text.split(' ')\n",
    "            for ind, token in enumerate(stroka):\n",
    "                #print(token)\n",
    "                if word == token:\n",
    "                    if token != stroka[-1]:\n",
    "                        words.append(stroka[ind+1])\n",
    "    \n",
    "        counts = Counter(words)\n",
    "        negative_dict[word] = counts.most_common(1000)\n",
    "        words = []\n",
    "#print(positive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'бедный': [('бедный', 2),\n",
       "  ('неразумный', 1),\n",
       "  ('врач', 1),\n",
       "  ('бабулька', 1),\n",
       "  ('мой', 1),\n",
       "  ('сосед', 1),\n",
       "  ('богатый', 1),\n",
       "  ('девица', 1),\n",
       "  ('неимущий', 1),\n",
       "  ('коренной', 1),\n",
       "  ('реал', 1),\n",
       "  ('влад', 1),\n",
       "  ('губка', 1),\n",
       "  ('печень', 1),\n",
       "  ('збежать', 1),\n",
       "  ('крестьянин', 1),\n",
       "  ('мишка', 1)],\n",
       " 'бесить': [('чувство', 1),\n",
       "  ('мама', 1),\n",
       "  ('ностальгировать', 1),\n",
       "  ('полярный', 1),\n",
       "  ('судить', 1),\n",
       "  ('весь', 1),\n",
       "  ('скучать', 1),\n",
       "  ('друг', 1),\n",
       "  ('смотреть', 1),\n",
       "  ('проблема', 1),\n",
       "  ('особенно', 1),\n",
       "  ('жлоб', 1),\n",
       "  ('мудоеб', 1),\n",
       "  ('болеть', 1),\n",
       "  ('человек', 1),\n",
       "  ('начинать', 1),\n",
       "  ('россия', 1),\n",
       "  ('тот', 1),\n",
       "  ('наивный', 1),\n",
       "  ('худой', 1),\n",
       "  ('писать', 1),\n",
       "  ('стоять', 1),\n",
       "  ('ты', 1)],\n",
       " 'блять': [('ебать', 2),\n",
       "  ('парень', 1),\n",
       "  ('сегодня', 1),\n",
       "  ('завтра', 1),\n",
       "  ('ахах', 1),\n",
       "  ('сук', 1),\n",
       "  ('нынче', 1),\n",
       "  ('каво', 1),\n",
       "  ('играть', 1),\n",
       "  ('гоу', 1),\n",
       "  ('ваш', 1),\n",
       "  ('видать', 1),\n",
       "  ('идти', 1),\n",
       "  ('перестать', 1),\n",
       "  ('фу', 1),\n",
       "  ('идиотииизм', 1),\n",
       "  ('совет', 1),\n",
       "  ('снег', 1),\n",
       "  ('зря', 1),\n",
       "  ('тя', 1),\n",
       "  ('сосед', 1),\n",
       "  ('настя', 1),\n",
       "  ('поиметь', 1),\n",
       "  ('набрать', 1),\n",
       "  ('хотеться', 1),\n",
       "  ('id5971215', 1),\n",
       "  ('охуесть', 1),\n",
       "  ('сука', 1),\n",
       "  ('звонок', 1),\n",
       "  ('идеальный', 1),\n",
       "  ('пропадать', 1),\n",
       "  ('сп', 1),\n",
       "  ('важный', 1),\n",
       "  ('пидорас', 1),\n",
       "  ('настроение', 1),\n",
       "  ('некоторый', 1),\n",
       "  ('восстание', 1),\n",
       "  ('охуевать', 1),\n",
       "  ('делать', 1),\n",
       "  ('просто', 1),\n",
       "  ('читать', 1),\n",
       "  ('сколько', 1),\n",
       "  ('снова', 1),\n",
       "  ('ужасно', 1),\n",
       "  ('мама', 1),\n",
       "  ('охуееш', 1),\n",
       "  ('это', 1),\n",
       "  ('скрин', 1),\n",
       "  ('сыграть', 1),\n",
       "  ('боммера', 1),\n",
       "  ('команда', 1),\n",
       "  ('обещать', 1),\n",
       "  ('стать', 1)],\n",
       " 'болеть': [('голова', 4),\n",
       "  ('поздний', 1),\n",
       "  ('выходной', 1),\n",
       "  ('ян', 1),\n",
       "  ('человек', 1),\n",
       "  ('блин', 1),\n",
       "  ('говорить', 1),\n",
       "  ('комната', 1),\n",
       "  ('взять', 1),\n",
       "  ('сильно', 1),\n",
       "  ('блять', 1),\n",
       "  ('шо', 1),\n",
       "  ('шахтёр', 1),\n",
       "  ('спасибо', 1),\n",
       "  ('мой', 1),\n",
       "  ('сердце', 1),\n",
       "  ('завтра', 1),\n",
       "  ('никто', 1),\n",
       "  ('ранний', 1),\n",
       "  ('один', 1),\n",
       "  ('ааа', 1),\n",
       "  ('глаз', 1),\n",
       "  ('красиво', 1),\n",
       "  ('поясница', 1),\n",
       "  ('лох', 1),\n",
       "  ('одиночество', 1),\n",
       "  ('дело', 1),\n",
       "  ('ужасно', 1),\n",
       "  ('нах', 1),\n",
       "  ('тот', 1),\n",
       "  ('пить', 1),\n",
       "  ('делать', 1)],\n",
       " 'больно': [('нужный', 2),\n",
       "  ('помнить', 2),\n",
       "  ('девушка', 2),\n",
       "  ('который', 2),\n",
       "  ('понимать', 2),\n",
       "  ('вспоминать', 1),\n",
       "  ('хочть', 1),\n",
       "  ('обидный', 1),\n",
       "  ('увидеть', 1),\n",
       "  ('долго', 1),\n",
       "  ('родной', 1),\n",
       "  ('больно', 1),\n",
       "  ('неунять', 1),\n",
       "  ('плохо', 1),\n",
       "  ('скучать', 1),\n",
       "  ('особенно', 1),\n",
       "  ('нравиться', 1),\n",
       "  ('страшно', 1),\n",
       "  ('выдеть', 1),\n",
       "  ('уходить', 1),\n",
       "  ('вчера', 1),\n",
       "  ('умирать', 1),\n",
       "  ('нести', 1),\n",
       "  ('давать', 1),\n",
       "  ('ваш', 1),\n",
       "  ('слышать', 1),\n",
       "  ('сделать', 1),\n",
       "  ('коптить', 1),\n",
       "  ('терять', 1),\n",
       "  ('это', 1),\n",
       "  ('весь', 1),\n",
       "  ('стать', 1),\n",
       "  ('очень', 1),\n",
       "  ('сей', 1)],\n",
       " 'бред': [('всякая', 1),\n",
       "  ('который', 1),\n",
       "  ('разабьешся', 1),\n",
       "  ('делать', 1),\n",
       "  ('зато', 1),\n",
       "  ('нести', 1),\n",
       "  ('безумие', 1),\n",
       "  ('сказать', 1),\n",
       "  ('тупой', 1),\n",
       "  ('непосредственно', 1),\n",
       "  ('наркоман', 1),\n",
       "  ('далбоёб', 1),\n",
       "  ('б', 1),\n",
       "  ('оказаться', 1),\n",
       "  ('быть', 1),\n",
       "  ('хотя', 1),\n",
       "  ('менее', 1)],\n",
       " 'брр': [],\n",
       " 'говно': [('руководство', 1),\n",
       "  ('выходной', 1),\n",
       "  ('видеть', 1),\n",
       "  ('нация', 1),\n",
       "  ('группа', 1),\n",
       "  ('вилка', 1),\n",
       "  ('баблом', 1),\n",
       "  ('дамашка', 1),\n",
       "  ('писать', 1),\n",
       "  ('давать', 1),\n",
       "  ('пойти', 1),\n",
       "  ('такой', 1),\n",
       "  ('вовсе', 1),\n",
       "  ('бояться', 1),\n",
       "  ('ебаной', 1),\n",
       "  ('который', 1),\n",
       "  ('дорога', 1)],\n",
       " 'грустить': [('вместе', 1),\n",
       "  ('герой', 1),\n",
       "  ('наташка', 1),\n",
       "  ('человечек', 1),\n",
       "  ('готовый', 1),\n",
       "  ('сдать', 1),\n",
       "  ('тишина', 1),\n",
       "  ('голубоглазенький', 1),\n",
       "  ('просто', 1),\n",
       "  ('забыть', 1),\n",
       "  ('голова', 1),\n",
       "  ('солдат', 1)],\n",
       " 'грустно': [('это', 2),\n",
       "  ('стать', 1),\n",
       "  ('очень', 1),\n",
       "  ('вроде', 1),\n",
       "  ('делать', 1),\n",
       "  ('теплиться', 1),\n",
       "  ('быстро', 1),\n",
       "  ('другой', 1),\n",
       "  ('нету', 1),\n",
       "  ('горняк', 1),\n",
       "  ('часть', 1),\n",
       "  ('любить', 1),\n",
       "  ('весело', 1),\n",
       "  ('фото', 1),\n",
       "  ('алин', 1),\n",
       "  ('значит', 1),\n",
       "  ('некого', 1),\n",
       "  ('плохо', 1),\n",
       "  ('утром', 1),\n",
       "  ('улыбаться', 1),\n",
       "  ('московский', 1),\n",
       "  ('равно', 1)],\n",
       " 'дебил': [('поздно', 2),\n",
       "  ('жениться', 2),\n",
       "  ('слушать', 2),\n",
       "  ('телевизор', 1),\n",
       "  ('пендос', 1),\n",
       "  ('голосовать', 1),\n",
       "  ('лайк', 1),\n",
       "  ('рассказовать', 1),\n",
       "  ('знаешь', 1),\n",
       "  ('мочь', 1),\n",
       "  ('cod', 1)],\n",
       " 'докатиться': [('вернуть', 1),\n",
       "  ('знать', 1),\n",
       "  ('прыщ', 1),\n",
       "  ('применение', 1),\n",
       "  ('жизнь', 1)],\n",
       " 'достать': [('раскурочить', 1),\n",
       "  ('случайный', 1),\n",
       "  ('стройка', 1),\n",
       "  ('нюша', 1),\n",
       "  ('гребаный', 1),\n",
       "  ('малость', 1),\n",
       "  ('пробка', 1),\n",
       "  ('никто', 1),\n",
       "  ('тыкваква', 1),\n",
       "  ('др', 1),\n",
       "  ('ты', 1),\n",
       "  ('деньга', 1),\n",
       "  ('охуэла', 1),\n",
       "  ('написать', 1),\n",
       "  ('это', 1),\n",
       "  ('псевдо', 1)],\n",
       " 'дура': [('прямо', 2),\n",
       "  ('овца', 1),\n",
       "  ('стремаешся', 1),\n",
       "  ('такой', 1),\n",
       "  ('худой', 1),\n",
       "  ('быя', 1),\n",
       "  ('тётя', 1),\n",
       "  ('везде', 1),\n",
       "  ('понять', 1),\n",
       "  ('больной', 1),\n",
       "  ('чак', 1),\n",
       "  ('болеть', 1),\n",
       "  ('уметь', 1),\n",
       "  ('который', 1)],\n",
       " 'жалко': [('бедный', 2),\n",
       "  ('уходить', 2),\n",
       "  ('эмоция', 1),\n",
       "  ('мужчина', 1),\n",
       "  ('юлька', 1),\n",
       "  ('покупать', 1),\n",
       "  ('мозги', 1),\n",
       "  ('стрыкать', 1),\n",
       "  ('заявка', 1),\n",
       "  ('такой', 1),\n",
       "  ('увидеться', 1),\n",
       "  ('ломать', 1),\n",
       "  ('девчонка', 1),\n",
       "  ('ребята', 1),\n",
       "  ('ещё', 1),\n",
       "  ('ехать', 1),\n",
       "  ('мочь', 1),\n",
       "  ('особенно', 1)],\n",
       " 'жаль': [('такой', 3),\n",
       "  ('память', 2),\n",
       "  ('жалко', 1),\n",
       "  ('верить', 1),\n",
       "  ('смотреть', 1),\n",
       "  ('очень', 1),\n",
       "  ('екб', 1),\n",
       "  ('далеко', 1),\n",
       "  ('именно', 1),\n",
       "  ('мечта', 1),\n",
       "  ('беременность', 1),\n",
       "  ('кенни', 1),\n",
       "  ('терять', 1),\n",
       "  ('клещ', 1),\n",
       "  ('правда', 1),\n",
       "  ('гудаури', 1),\n",
       "  ('родиться', 1),\n",
       "  ('вернуть', 1),\n",
       "  ('слышать', 1),\n",
       "  ('некоторый', 1),\n",
       "  ('немного', 1),\n",
       "  ('детище', 1),\n",
       "  ('это', 1),\n",
       "  ('впереди', 1),\n",
       "  ('ряд', 1),\n",
       "  ('город', 1),\n",
       "  ('путь', 1),\n",
       "  ('14', 1),\n",
       "  ('тролль', 1),\n",
       "  ('мальчик', 1),\n",
       "  ('парень', 1),\n",
       "  ('россия', 1),\n",
       "  ('сегодня', 1),\n",
       "  ('справиться', 1),\n",
       "  ('соnтr', 1),\n",
       "  ('половина', 1),\n",
       "  ('улететь', 1),\n",
       "  ('мой', 1),\n",
       "  ('кроме', 1),\n",
       "  ('черта', 1),\n",
       "  ('слово', 1),\n",
       "  ('утомлённый', 1),\n",
       "  ('дацюк', 1),\n",
       "  ('тяжело', 1),\n",
       "  ('знать', 1),\n",
       "  ('поздно', 1),\n",
       "  ('22', 1),\n",
       "  ('твой', 1),\n",
       "  ('политический', 1)],\n",
       " 'заболеть': [('думать', 1),\n",
       "  ('обидный', 1),\n",
       "  ('окружающий', 1),\n",
       "  ('пингвена', 1),\n",
       "  ('чувствовать', 1),\n",
       "  ('приезжать', 1),\n",
       "  ('день', 1),\n",
       "  ('летом', 1),\n",
       "  ('супчик', 1),\n",
       "  ('самый', 1)],\n",
       " 'забыть': [('это', 3),\n",
       "  ('свой', 3),\n",
       "  ('гордость', 2),\n",
       "  ('любить', 2),\n",
       "  ('сказать', 2),\n",
       "  ('старое', 2),\n",
       "  ('день', 2),\n",
       "  ('помнить', 2),\n",
       "  ('спросить', 1),\n",
       "  ('долбаный', 1),\n",
       "  ('минутка', 1),\n",
       "  ('кинуть', 1),\n",
       "  ('откуда', 1),\n",
       "  ('затем', 1),\n",
       "  ('одеть', 1),\n",
       "  ('лето', 1),\n",
       "  ('деньга', 1),\n",
       "  ('грустить', 1),\n",
       "  ('бе', 1),\n",
       "  ('завтра', 1),\n",
       "  ('наверное', 1),\n",
       "  ('кошелёк', 1),\n",
       "  ('крошка', 1),\n",
       "  ('дибить', 1),\n",
       "  ('банзайчик', 1),\n",
       "  ('многий', 1),\n",
       "  ('боль', 1),\n",
       "  ('футбол', 1),\n",
       "  ('очень', 1),\n",
       "  ('санька', 1),\n",
       "  ('зазнаться', 1),\n",
       "  ('дописать', 1),\n",
       "  ('унизить', 1),\n",
       "  ('место', 1),\n",
       "  ('смочь', 1),\n",
       "  ('такоe', 1),\n",
       "  ('жалко', 1),\n",
       "  ('один', 1),\n",
       "  ('святой', 1),\n",
       "  ('быть', 1),\n",
       "  ('жизнь', 1),\n",
       "  ('твой', 1),\n",
       "  ('отчаяние', 1),\n",
       "  ('момент', 1),\n",
       "  ('зашить', 1),\n",
       "  ('вспоминать', 1),\n",
       "  ('счастливый', 1),\n",
       "  ('ехать', 1),\n",
       "  ('царство', 1),\n",
       "  ('просто', 1),\n",
       "  ('прикрепить', 1)],\n",
       " 'зло': [('это', 1),\n",
       "  ('кто', 1),\n",
       "  ('мотаться', 1),\n",
       "  ('5', 1),\n",
       "  ('губа', 1),\n",
       "  ('враг', 1),\n",
       "  ('фр', 1),\n",
       "  ('вместе', 1),\n",
       "  ('этот', 1),\n",
       "  ('бодрый', 1),\n",
       "  ('дерзить', 1),\n",
       "  ('либо', 1),\n",
       "  ('оттого', 1)],\n",
       " 'идиот': [('стыдно', 2),\n",
       "  ('id8877221', 1),\n",
       "  ('журавлев', 1),\n",
       "  ('копейка', 1),\n",
       "  ('остаться', 1),\n",
       "  ('карий', 1),\n",
       "  ('санки', 1),\n",
       "  ('форум', 1),\n",
       "  ('оптимист', 1),\n",
       "  ('убить', 1),\n",
       "  ('придумать', 1),\n",
       "  ('сюжет', 1),\n",
       "  ('мерзавец', 1),\n",
       "  ('доинтернетной', 1)],\n",
       " 'кошмар': [('превратить', 1), ('сниться', 1), ('хотеть', 1), ('соседка', 1)],\n",
       " 'лох': [('значит', 2),\n",
       "  ('ссаный', 1),\n",
       "  ('шадрина', 1),\n",
       "  ('чмо', 1),\n",
       "  ('звукооператор', 1),\n",
       "  ('помогать', 1),\n",
       "  ('ебу', 1),\n",
       "  ('далёкий', 1),\n",
       "  ('шева', 1),\n",
       "  ('найти', 1)],\n",
       " 'мудак': [('хотеться', 1),\n",
       "  ('мудак', 1),\n",
       "  ('краснов', 1),\n",
       "  ('ебаный', 1),\n",
       "  ('мразь', 1),\n",
       "  ('понять', 1)],\n",
       " 'надоесть': [('вообще', 2),\n",
       "  ('лёд', 1),\n",
       "  ('ааа', 1),\n",
       "  ('приставать', 1),\n",
       "  ('звонить', 1),\n",
       "  ('красавитя', 1),\n",
       "  ('ссаный', 1),\n",
       "  ('стараться', 1),\n",
       "  ('передвижение', 1),\n",
       "  ('совими', 1),\n",
       "  ('больница', 1),\n",
       "  ('сниться', 1),\n",
       "  ('хотеть', 1),\n",
       "  ('бляха', 1),\n",
       "  ('зима', 1),\n",
       "  ('изменение', 1),\n",
       "  ('слушать', 1),\n",
       "  ('сук', 1),\n",
       "  ('пересматривать', 1),\n",
       "  ('читать', 1),\n",
       "  ('взрослый', 1),\n",
       "  ('открывать', 1),\n",
       "  ('большой', 1)],\n",
       " 'нахрен': [('сдаться', 2),\n",
       "  ('вообще', 1),\n",
       "  ('спать', 1),\n",
       "  ('мартин', 1),\n",
       "  ('попереться', 1),\n",
       "  ('бухать', 1),\n",
       "  ('это', 1),\n",
       "  ('твай', 1),\n",
       "  ('столько', 1),\n",
       "  ('египтянин', 1),\n",
       "  ('осень', 1),\n",
       "  ('нужный', 1),\n",
       "  ('давать', 1),\n",
       "  ('уважаемый', 1)],\n",
       " 'ненавидеть': [('алкоголь', 2),\n",
       "  ('враньё', 2),\n",
       "  ('придурок', 2),\n",
       "  ('наш', 2),\n",
       "  ('виндовс', 2),\n",
       "  ('обобщение', 2),\n",
       "  ('человек', 2),\n",
       "  ('писать', 1),\n",
       "  ('время', 1),\n",
       "  ('это', 1),\n",
       "  ('мирэ', 1),\n",
       "  ('понедельник', 1),\n",
       "  ('ты', 1),\n",
       "  ('пытаться', 1),\n",
       "  ('репа', 1),\n",
       "  ('такой', 1),\n",
       "  ('зонт', 1),\n",
       "  ('комаров', 1),\n",
       "  ('выходной', 1),\n",
       "  ('хотеть', 1),\n",
       "  ('тот', 1),\n",
       "  ('утром', 1),\n",
       "  ('спина', 1),\n",
       "  ('ссыкун', 1),\n",
       "  ('пять', 1),\n",
       "  ('закрыть', 1),\n",
       "  ('белить', 1),\n",
       "  ('валик', 1),\n",
       "  ('прощаться', 1),\n",
       "  ('друг', 1),\n",
       "  ('купить', 1),\n",
       "  ('работа', 1),\n",
       "  ('какой', 1),\n",
       "  ('канадец', 1),\n",
       "  ('мой', 1),\n",
       "  ('пидоров', 1),\n",
       "  ('они', 1),\n",
       "  ('сессия', 1),\n",
       "  ('двигатель', 1)],\n",
       " 'обидный': [('человек', 4),\n",
       "  ('осознавать', 3),\n",
       "  ('наверное', 1),\n",
       "  ('душить', 1),\n",
       "  ('кстат', 1),\n",
       "  ('сукааа', 1),\n",
       "  ('никто', 1),\n",
       "  ('твой', 1),\n",
       "  ('жена', 1),\n",
       "  ('15', 1),\n",
       "  ('работа', 1),\n",
       "  ('такой', 1),\n",
       "  ('читать', 1),\n",
       "  ('тянуться', 1),\n",
       "  ('последний', 1),\n",
       "  ('говорят', 1),\n",
       "  ('становиться', 1),\n",
       "  ('c', 1),\n",
       "  ('родина', 1)],\n",
       " 'одиночество': [('время', 1),\n",
       "  ('школа', 1),\n",
       "  ('низшество', 1),\n",
       "  ('который', 1),\n",
       "  ('мой', 1),\n",
       "  ('это', 1),\n",
       "  ('заметный', 1),\n",
       "  ('заестись', 1),\n",
       "  ('вроде', 1),\n",
       "  ('затеряться', 1),\n",
       "  ('словно', 1)],\n",
       " 'олень': [('это', 1), ('многостаночный', 1), ('вылететь', 1)],\n",
       " 'печаль': [('радость', 2),\n",
       "  ('окутывать', 1),\n",
       "  ('сосать', 1),\n",
       "  ('знакомый', 1),\n",
       "  ('пессимизм', 1),\n",
       "  ('запрятать', 1),\n",
       "  ('стоить', 1),\n",
       "  ('соболезнование', 1),\n",
       "  ('этот', 1),\n",
       "  ('бровь', 1),\n",
       "  ('отныне', 1),\n",
       "  ('пусть', 1),\n",
       "  ('жаль', 1)],\n",
       " 'пиздец': [('просто', 4),\n",
       "  ('это', 2),\n",
       "  ('представлять', 1),\n",
       "  ('надеяться', 1),\n",
       "  ('конец', 1),\n",
       "  ('тормоз', 1),\n",
       "  ('поламаленький', 1),\n",
       "  ('мой', 1),\n",
       "  ('блять', 1),\n",
       "  ('народ', 1),\n",
       "  ('работа', 1),\n",
       "  ('ящетая', 1),\n",
       "  ('весь', 1),\n",
       "  ('неудобно', 1),\n",
       "  ('охуенно', 1),\n",
       "  ('служить', 1),\n",
       "  ('спалиться', 1),\n",
       "  ('наблюдать', 1),\n",
       "  ('утешительный', 1),\n",
       "  ('сосед', 1),\n",
       "  ('стена', 1),\n",
       "  ('открыть', 1),\n",
       "  ('хахла', 1),\n",
       "  ('шпана', 1),\n",
       "  ('причём', 1),\n",
       "  ('пешеход', 1),\n",
       "  ('подкрасться', 1),\n",
       "  ('вьебали', 1),\n",
       "  ('знать', 1),\n",
       "  ('хороший', 1),\n",
       "  ('сукиия', 1),\n",
       "  ('товарищ', 1),\n",
       "  ('отношение', 1),\n",
       "  ('какой', 1),\n",
       "  ('мыть', 1),\n",
       "  ('нужно', 1),\n",
       "  ('атр', 1),\n",
       "  ('хотя', 1),\n",
       "  ('похуй', 1),\n",
       "  ('админ', 1),\n",
       "  ('шокировать', 1),\n",
       "  ('посмотреть', 1),\n",
       "  ('vk', 1),\n",
       "  ('гламурный', 1)],\n",
       " 'плохо': [('весь', 2),\n",
       "  ('погрустить', 2),\n",
       "  ('влад', 1),\n",
       "  ('скучать', 1),\n",
       "  ('американка', 1),\n",
       "  ('похуй', 1),\n",
       "  ('стать', 1),\n",
       "  ('весьма', 1),\n",
       "  ('думать', 1),\n",
       "  ('немощно', 1),\n",
       "  ('знать', 1),\n",
       "  ('сказать', 1),\n",
       "  ('вокруг', 1),\n",
       "  ('спасть', 1),\n",
       "  ('рой', 1),\n",
       "  ('ошибаешся', 1),\n",
       "  ('заболеть', 1),\n",
       "  ('отдыхать', 1),\n",
       "  ('тяжело', 1),\n",
       "  ('гулять', 1),\n",
       "  ('растянуть', 1),\n",
       "  ('брать', 1),\n",
       "  ('верить', 1),\n",
       "  ('моральный', 1),\n",
       "  ('чувствовать', 1),\n",
       "  ('относиться', 1),\n",
       "  ('таков', 1),\n",
       "  ('казаться', 1),\n",
       "  ('бухнуть', 1),\n",
       "  ('написать', 1),\n",
       "  ('наш', 1),\n",
       "  ('ансамбль', 1),\n",
       "  ('хороший', 1),\n",
       "  ('беречь', 1),\n",
       "  ('житься', 1),\n",
       "  ('никто', 1),\n",
       "  ('пролетать', 1),\n",
       "  ('злой', 1),\n",
       "  ('хотеть', 1),\n",
       "  ('понимать', 1),\n",
       "  ('леди', 1)],\n",
       " 'подонок': [('поэтому', 1), ('вспомниться', 1), ('мужик', 1)],\n",
       " 'послать': [('нахуй', 3),\n",
       "  ('это', 2),\n",
       "  ('школа', 2),\n",
       "  ('весь', 2),\n",
       "  ('друг', 1),\n",
       "  ('оплатить', 1),\n",
       "  ('рука', 1),\n",
       "  ('нахер', 1),\n",
       "  ('прах', 1),\n",
       "  ('готовый', 1),\n",
       "  ('уйти', 1),\n",
       "  ('пу', 1),\n",
       "  ('приходящий', 1),\n",
       "  ('я', 1),\n",
       "  ('жопа', 1),\n",
       "  ('сучка', 1),\n",
       "  ('гулять', 1),\n",
       "  ('дружно', 1),\n",
       "  ('забыть', 1),\n",
       "  ('никчёмный', 1),\n",
       "  ('поход', 1)],\n",
       " 'ппц': [('зуб', 1),\n",
       "  ('короче', 1),\n",
       "  ('люююдить', 1),\n",
       "  ('суббота', 1),\n",
       "  ('прочитать', 1),\n",
       "  ('красиивааа', 1),\n",
       "  ('сломать', 1),\n",
       "  ('хотеться', 1),\n",
       "  ('сегодня', 1),\n",
       "  ('настать', 1),\n",
       "  ('стол', 1),\n",
       "  ('просто', 1),\n",
       "  ('ахахахах', 1),\n",
       "  ('слушать', 1)],\n",
       " 'скорбеть': [('ребята', 1), ('14', 1), ('братишка', 1)],\n",
       " 'скучно': [('жить', 1),\n",
       "  ('мочь', 1),\n",
       "  ('вонять', 1),\n",
       "  ('хотеть', 1),\n",
       "  ('любить', 1),\n",
       "  ('значит', 1),\n",
       "  ('солнышко', 1),\n",
       "  ('весь', 1),\n",
       "  ('делать', 1),\n",
       "  ('дежурить', 1),\n",
       "  ('грустно', 1),\n",
       "  ('оба', 1),\n",
       "  ('быстро', 1)],\n",
       " 'смерть': [('жизнь', 1),\n",
       "  ('шавка', 1),\n",
       "  ('другой', 1),\n",
       "  ('сила', 1),\n",
       "  ('зима', 1),\n",
       "  ('похуй', 1),\n",
       "  ('мы', 1),\n",
       "  ('москаль', 1),\n",
       "  ('страшный', 1),\n",
       "  ('беда', 1),\n",
       "  ('пустить', 1),\n",
       "  ('посвящаться', 1),\n",
       "  ('один', 1),\n",
       "  ('это', 1),\n",
       "  ('весь', 1),\n",
       "  ('ребёнок', 1)],\n",
       " 'тварь': [('ненавидеть', 1),\n",
       "  ('слово', 1),\n",
       "  ('бездушный', 1),\n",
       "  ('обойти', 1),\n",
       "  ('засуетиться', 1),\n",
       "  ('идти', 1),\n",
       "  ('спать', 1),\n",
       "  ('весь', 1),\n",
       "  ('любить', 1),\n",
       "  ('аладин', 1),\n",
       "  ('вновь', 1),\n",
       "  ('уберегать', 1)],\n",
       " 'тормоз': [('почему', 1), ('оля', 1), ('бывать', 1)],\n",
       " 'тупой': [('идиот', 3),\n",
       "  ('овца', 2),\n",
       "  ('пёзд', 2),\n",
       "  ('мясорубка', 1),\n",
       "  ('ванильный', 1),\n",
       "  ('мим', 1),\n",
       "  ('пиздюк', 1),\n",
       "  ('зубрёжка', 1),\n",
       "  ('поебеня', 1),\n",
       "  ('хохлянский', 1),\n",
       "  ('пездами', 1),\n",
       "  ('мир', 1),\n",
       "  ('нелзя', 1),\n",
       "  ('муха', 1),\n",
       "  ('недоебок', 1),\n",
       "  ('думать', 1)],\n",
       " 'убивать': [('дом', 1),\n",
       "  ('скрыть', 1),\n",
       "  ('долго', 1),\n",
       "  ('депортировать', 1),\n",
       "  ('выстрел', 1),\n",
       "  ('население', 1),\n",
       "  ('человек', 1),\n",
       "  ('безоружный', 1),\n",
       "  ('насиловать', 1),\n",
       "  ('чувство', 1),\n",
       "  ('статус', 1)],\n",
       " 'ужас': [('серьёзно', 1),\n",
       "  ('65', 1),\n",
       "  ('соболезновать', 1),\n",
       "  ('фильм', 1),\n",
       "  ('страх', 1),\n",
       "  ('десятка', 1),\n",
       "  ('прям', 1),\n",
       "  ('16', 1),\n",
       "  ('кровь', 1),\n",
       "  ('выглядеть', 1)],\n",
       " 'ужасный': [('это', 2),\n",
       "  ('время', 2),\n",
       "  ('день', 1),\n",
       "  ('зрелище', 1),\n",
       "  ('катастрофа', 1),\n",
       "  ('ветер', 1),\n",
       "  ('удалять', 1),\n",
       "  ('чувство', 1),\n",
       "  ('трагедия', 1),\n",
       "  ('замес', 1),\n",
       "  ('настроение', 1),\n",
       "  ('прогресс', 1),\n",
       "  ('экология', 1),\n",
       "  ('подробность', 1),\n",
       "  ('парень', 1),\n",
       "  ('человек', 1)],\n",
       " 'умереть': [('вспомнить', 1),\n",
       "  ('обмануть', 1),\n",
       "  ('ты', 1),\n",
       "  ('прощать', 1),\n",
       "  ('воспаление', 1),\n",
       "  ('называться', 1),\n",
       "  ('p', 1),\n",
       "  ('предвкушение', 1),\n",
       "  ('специально', 1),\n",
       "  ('январь', 1),\n",
       "  ('кумир', 1),\n",
       "  ('курт', 1),\n",
       "  ('7', 1),\n",
       "  ('никто', 1),\n",
       "  ('настоящий', 1),\n",
       "  ('хотеться', 1),\n",
       "  ('бояться', 1),\n",
       "  ('by', 1),\n",
       "  ('грех', 1),\n",
       "  ('дом', 1),\n",
       "  ('папа', 1),\n",
       "  ('родной', 1),\n",
       "  ('расплакаться', 1),\n",
       "  ('никакой', 1),\n",
       "  ('вси', 1),\n",
       "  ('исчезнуть', 1),\n",
       "  ('лягушка', 1),\n",
       "  ('нахуй', 1),\n",
       "  ('это', 1),\n",
       "  ('бендеры', 1),\n",
       "  ('хоронить', 1),\n",
       "  ('вместе', 1),\n",
       "  ('катя', 1)],\n",
       " 'хватить': [('думать', 2),\n",
       "  ('гулять', 1),\n",
       "  ('косячить', 1),\n",
       "  ('шляться', 1),\n",
       "  ('близкий', 1),\n",
       "  ('полчаса', 1),\n",
       "  ('прятаться', 1),\n",
       "  ('праздновать', 1),\n",
       "  ('любить', 1),\n",
       "  ('одобрять', 1),\n",
       "  ('фотка', 1),\n",
       "  ('метр', 1),\n",
       "  ('нерв', 1),\n",
       "  ('обмататься', 1),\n",
       "  ('воевать', 1),\n",
       "  ('ржать', 1),\n",
       "  ('гарусный', 1),\n",
       "  ('глумиться', 1),\n",
       "  ('погнать', 1),\n",
       "  ('игнорить', 1),\n",
       "  ('кормить', 1),\n",
       "  ('распыляться', 1),\n",
       "  ('разрушать', 1),\n",
       "  ('слушать', 1),\n",
       "  ('место', 1),\n",
       "  ('тоска', 1),\n",
       "  ('ахаххахах', 1),\n",
       "  ('один', 1),\n",
       "  ('злить', 1),\n",
       "  ('писать', 1),\n",
       "  ('разговаривать', 1),\n",
       "  ('графон', 1),\n",
       "  ('голливуд', 1),\n",
       "  ('развратный', 1),\n",
       "  ('черта', 1),\n",
       "  ('пока', 1),\n",
       "  ('проигрывать', 1)],\n",
       " 'хер': [('пара', 1),\n",
       "  ('сгореть', 1),\n",
       "  ('заеесть', 1),\n",
       "  ('собачий', 1),\n",
       "  ('мы', 1),\n",
       "  ('докуривать', 1),\n",
       "  ('рассинхронизироваться', 1)],\n",
       " 'хреновый': [('луч', 1),\n",
       "  ('путешественник', 1),\n",
       "  ('болеть', 1),\n",
       "  ('боль', 1),\n",
       "  ('прийтись', 1),\n",
       "  ('состояние', 1),\n",
       "  ('конец', 1),\n",
       "  ('ужас', 1)],\n",
       " 'хулить': [('правильно', 1),\n",
       "  ('домашний', 1),\n",
       "  ('жить', 1),\n",
       "  ('базарить', 1),\n",
       "  ('статус', 1),\n",
       "  ('хвастаться', 1),\n",
       "  ('мелочиться', 1),\n",
       "  ('танцор', 1),\n",
       "  ('гулять', 1),\n",
       "  ('гавный', 1),\n",
       "  ('остальной', 1)]}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "СЛОВО скучно, Количество дистрибуций: 13\n",
      "СЛОВО пиздец, Количество дистрибуций: 44\n",
      "СЛОВО говно, Количество дистрибуций: 17\n",
      "СЛОВО ненавидеть, Количество дистрибуций: 39\n",
      "СЛОВО жалко, Количество дистрибуций: 18\n",
      "СЛОВО заболеть, Количество дистрибуций: 10\n",
      "СЛОВО грустно, Количество дистрибуций: 22\n",
      "СЛОВО блять, Количество дистрибуций: 53\n",
      "СЛОВО умереть, Количество дистрибуций: 33\n",
      "СЛОВО лох, Количество дистрибуций: 10\n",
      "СЛОВО болеть, Количество дистрибуций: 32\n",
      "СЛОВО жаль, Количество дистрибуций: 49\n",
      "СЛОВО плохо, Количество дистрибуций: 41\n",
      "СЛОВО послать, Количество дистрибуций: 21\n",
      "СЛОВО убивать, Количество дистрибуций: 11\n",
      "СЛОВО надоесть, Количество дистрибуций: 23\n",
      "СЛОВО ужасный, Количество дистрибуций: 16\n",
      "СЛОВО бред, Количество дистрибуций: 17\n",
      "СЛОВО обидный, Количество дистрибуций: 19\n",
      "СЛОВО ппц, Количество дистрибуций: 14\n",
      "СЛОВО достать, Количество дистрибуций: 16\n",
      "СЛОВО ужас, Количество дистрибуций: 10\n",
      "СЛОВО хватить, Количество дистрибуций: 37\n",
      "СЛОВО хреновый, Количество дистрибуций: 8\n",
      "СЛОВО дура, Количество дистрибуций: 14\n",
      "СЛОВО тормоз, Количество дистрибуций: 3\n",
      "СЛОВО тупой, Количество дистрибуций: 16\n",
      "СЛОВО смерть, Количество дистрибуций: 16\n",
      "СЛОВО скорбеть, Количество дистрибуций: 3\n",
      "СЛОВО дебил, Количество дистрибуций: 11\n",
      "СЛОВО идиот, Количество дистрибуций: 14\n",
      "СЛОВО хер, Количество дистрибуций: 7\n",
      "СЛОВО подонок, Количество дистрибуций: 3\n",
      "СЛОВО хулить, Количество дистрибуций: 11\n",
      "СЛОВО одиночество, Количество дистрибуций: 11\n",
      "СЛОВО кошмар, Количество дистрибуций: 4\n",
      "СЛОВО забыть, Количество дистрибуций: 51\n",
      "СЛОВО бедный, Количество дистрибуций: 17\n",
      "СЛОВО нахрен, Количество дистрибуций: 14\n",
      "СЛОВО олень, Количество дистрибуций: 3\n",
      "СЛОВО докатиться, Количество дистрибуций: 5\n",
      "СЛОВО тварь, Количество дистрибуций: 12\n",
      "СЛОВО больно, Количество дистрибуций: 34\n",
      "СЛОВО печаль, Количество дистрибуций: 13\n",
      "СЛОВО бесить, Количество дистрибуций: 23\n",
      "СЛОВО зло, Количество дистрибуций: 13\n",
      "СЛОВО брр, Количество дистрибуций: 0\n",
      "СЛОВО грустить, Количество дистрибуций: 12\n",
      "СЛОВО мудак, Количество дистрибуций: 6\n"
     ]
    }
   ],
   "source": [
    "for i in negative_dict:\n",
    "    print('СЛОВО ' + i + ', Количество дистрибуций: ' + str(len(negative_dict[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "СЛОВО ахи, Количество дистрибуций: 24\n",
      "СЛОВО крутой, Количество дистрибуций: 56\n",
      "СЛОВО прекрасный, Количество дистрибуций: 56\n",
      "СЛОВО обожать, Количество дистрибуций: 36\n",
      "СЛОВО понравиться, Количество дистрибуций: 36\n",
      "СЛОВО отличный, Количество дистрибуций: 52\n",
      "СЛОВО ура, Количество дистрибуций: 40\n",
      "СЛОВО классный, Количество дистрибуций: 44\n",
      "СЛОВО хороший, Количество дистрибуций: 247\n",
      "СЛОВО круто, Количество дистрибуций: 34\n",
      "СЛОВО шикарный, Количество дистрибуций: 31\n",
      "СЛОВО приятно, Количество дистрибуций: 36\n",
      "СЛОВО любимый, Количество дистрибуций: 169\n",
      "СЛОВО ахахахах, Количество дистрибуций: 9\n",
      "СЛОВО супер, Количество дистрибуций: 30\n",
      "СЛОВО красивый, Количество дистрибуций: 79\n",
      "СЛОВО любить, Количество дистрибуций: 299\n",
      "СЛОВО счастие, Количество дистрибуций: 88\n",
      "СЛОВО замечательный, Количество дистрибуций: 34\n",
      "СЛОВО офигенный, Количество дистрибуций: 9\n",
      "СЛОВО красиво, Количество дистрибуций: 23\n",
      "СЛОВО молодец, Количество дистрибуций: 25\n",
      "СЛОВО прикольный, Количество дистрибуций: 15\n",
      "СЛОВО нравиться, Количество дистрибуций: 43\n",
      "СЛОВО красавчик, Количество дистрибуций: 9\n",
      "СЛОВО идеальный, Количество дистрибуций: 20\n",
      "СЛОВО охуенно, Количество дистрибуций: 2\n",
      "СЛОВО еее, Количество дистрибуций: 8\n",
      "СЛОВО красавец, Количество дистрибуций: 4\n",
      "СЛОВО наслаждаться, Количество дистрибуций: 12\n",
      "СЛОВО тащиться, Количество дистрибуций: 6\n",
      "СЛОВО улыбнуться, Количество дистрибуций: 15\n",
      "СЛОВО счастливый, Количество дистрибуций: 68\n",
      "СЛОВО отлично, Количество дистрибуций: 25\n",
      "СЛОВО классно, Количество дистрибуций: 14\n",
      "СЛОВО милый, Количество дистрибуций: 56\n",
      "СЛОВО ржать, Количество дистрибуций: 7\n",
      "СЛОВО слава, Количество дистрибуций: 24\n",
      "СЛОВО чемпион, Количество дистрибуций: 11\n",
      "СЛОВО подруга, Количество дистрибуций: 59\n",
      "СЛОВО здорово, Количество дистрибуций: 14\n",
      "СЛОВО удача, Количество дистрибуций: 16\n",
      "СЛОВО чудесный, Количество дистрибуций: 17\n",
      "СЛОВО влюбиться, Количество дистрибуций: 14\n",
      "СЛОВО родной, Количество дистрибуций: 56\n",
      "СЛОВО гордиться, Количество дистрибуций: 11\n",
      "СЛОВО трек, Количество дистрибуций: 31\n",
      "СЛОВО правда, Количество дистрибуций: 66\n",
      "СЛОВО красота, Количество дистрибуций: 24\n",
      "СЛОВО довольный, Количество дистрибуций: 15\n",
      "СЛОВО танцевать, Количество дистрибуций: 16\n"
     ]
    }
   ],
   "source": [
    "for i in positive_dict:\n",
    "    print('СЛОВО ' + i + ', Количество дистрибуций: ' + str(len(positive_dict[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Репрезентация TF-IDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаем объект класса TF-IDF Vectorizer, который преобразует корпус текстов в TF-IDF\n",
    "TFIDFVectorizer = TfidfVectorizer(max_df=0.9, min_df=0.01, sublinear_tf=True)\n",
    "X_TF = TFIDFVectorizer.fit_transform(X)\n",
    "\n",
    "# Тогда разбить на тренировочную\\тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_TF, labelled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6559\n",
      "Precision: 0.6559\n",
      "Recall: 0.6559\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.24      0.35       761\n",
      "          1       0.65      0.92      0.77      1192\n",
      "\n",
      "avg / total       0.66      0.66      0.60      1953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создаем объект класса логистической регрессии\n",
    "logistic_model = LogisticRegression()  \n",
    "logistic_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "predicted = logistic_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "\n",
    "# Указываем micro\\macro, поскольку у нас три класса, т.е. мультиклассовая классификация\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(predicted, y_test)))\n",
    "print('Precision: {:0.4f}'.format(precision_score(predicted, y_test, average = 'micro')))\n",
    "print('Recall: {:0.4f}'.format(recall_score(predicted, y_test, average = 'micro')))\n",
    "\n",
    "print(classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy list: [0.66513057 0.67434716 0.66461854 0.65540195 0.66752049]\n",
      "Mean of accuracy list: 0.6654 (+/- 0.0061)\n"
     ]
    }
   ],
   "source": [
    "# Рассмотрим более консервативную оценку с помощью кросс-валидации\n",
    "# Реализуем сначала самую простую оценку\n",
    "\n",
    "accuracy_list = cross_val_score(logistic_model, X_TF, labelled_y, cv=5)   # Возвращает список score (в нашем случае это accuracy)\n",
    "print('Accuracy list: {}'.format(accuracy_list))\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 | Accuracy: 0.6733 | Precision: 0.6733 | Recall: 0.6733 | F1-score: 0.6733 \n",
      "Iteration #2 | Accuracy: 0.7066 | Precision: 0.7066 | Recall: 0.7066 | F1-score: 0.7066 \n",
      "Iteration #3 | Accuracy: 0.7025 | Precision: 0.7025 | Recall: 0.7025 | F1-score: 0.7025 \n",
      "Iteration #4 | Accuracy: 0.5581 | Precision: 0.5581 | Recall: 0.5581 | F1-score: 0.5581 \n",
      "Iteration #5 | Accuracy: 0.6773 | Precision: 0.6773 | Recall: 0.6773 | F1-score: 0.6773 \n",
      "Mean of accuracy list: 0.6636 (+/- 0.0544)\n",
      "Mean of precision list: 0.6636 (+/- 0.0544)\n",
      "Mean of recall list: 0.6636 (+/- 0.0544)\n",
      "Mean of f1 score list: 0.6636 (+/- 0.0544)\n"
     ]
    }
   ],
   "source": [
    "# Теперь реализуем посредством того, что мы сами будем разбивать\n",
    "kf = KFold(n_splits=5)\n",
    "iter_number = 0\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_measure_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_TF):\n",
    "    iter_number += 1\n",
    "    X_train, X_test = X_TF[train_index], X_TF[test_index]\n",
    "    y_train, y_test = labelled_y[train_index], labelled_y[test_index]\n",
    "    \n",
    "    logistic_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "    predicted = logistic_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "\n",
    "    # Указываем micro\\macro, поскольку у нас три класса, т.е. мультиклассовая классификация\n",
    "    \n",
    "    print('Iteration #{} | Accuracy: {:0.4f} | Precision: {:0.4f} | Recall: {:0.4f} | F1-score: {:0.4f} '.format(\n",
    "        iter_number,\n",
    "        accuracy_score(predicted, y_test),\n",
    "        precision_score(predicted, y_test, average = 'micro'),\n",
    "        recall_score(predicted, y_test, average = 'micro'),\n",
    "        f1_score(predicted, y_test, average = 'micro')\n",
    "    ))\n",
    "    accuracy_list.append(accuracy_score(predicted, y_test))\n",
    "    precision_list.append(precision_score(predicted, y_test, average = 'micro'))\n",
    "    recall_list.append(recall_score(predicted, y_test, average = 'micro'))\n",
    "    f1_measure_list.append(f1_score(predicted, y_test, average = 'micro'))\n",
    "\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))\n",
    "print('Mean of precision list: {:.4f} (+/- {:.4f})'.format(np.mean(precision_list), np.std(precision_list)))\n",
    "print('Mean of recall list: {:.4f} (+/- {:.4f})'.format(np.mean(recall_list), np.std(recall_list)))\n",
    "print('Mean of f1 score list: {:.4f} (+/- {:.4f})'.format(np.mean(f1_measure_list), np.std(f1_measure_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение предсказаний ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labelled_y, test_size=0.2)\n",
    "\n",
    "vec = TfidfVectorizer(max_df=0.9, min_df=0.01, sublinear_tf=True, ngram_range=(1,2))\n",
    "\n",
    "\n",
    "clf = LogisticRegressionCV()   \n",
    "\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.28      0.39       707\n",
      "          1       0.69      0.91      0.79      1246\n",
      "\n",
      "avg / total       0.67      0.68      0.64      1953\n",
      "\n",
      "accuracy: 0.684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        #target_names=twenty_test.target_names\n",
    "                                          )\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dns\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "df = eli5.explain_weights_df(clf, vec=vec,\n",
    "                 target_names=classEncoder.classes_\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('bayes_linregr_tfidf_pred.txt', sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Репрезентация CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Создаем объект класса CountVectorizer, который преобразует корпус текстов в one-hot представление\n",
    "CVectorizer = CountVectorizer()\n",
    "X_Count = CVectorizer.fit_transform(X)\n",
    "\n",
    "# Тогда разбить на тренировочную\\тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Count, labelled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8095\n",
      "Precision: 0.8095\n",
      "Recall: 0.8095\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.61      0.71       735\n",
      "          1       0.80      0.93      0.86      1218\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создаем объект класса логистической регрессии\n",
    "logistic_model = LogisticRegression()  \n",
    "logistic_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "predicted = logistic_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "\n",
    "# Указываем micro\\macro, поскольку у нас три класса, т.е. мультиклассовая классификация\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(predicted, y_test)))\n",
    "print('Precision: {:0.4f}'.format(precision_score(predicted, y_test, average = 'micro')))\n",
    "print('Recall: {:0.4f}'.format(recall_score(predicted, y_test, average = 'micro')))\n",
    "\n",
    "print(classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy list: [0.79313876 0.80030722 0.80286738 0.79774706 0.79815574]\n",
      "Mean of accuracy list: 0.7984 (+/- 0.0032)\n"
     ]
    }
   ],
   "source": [
    "# Рассмотрим более консервативную оценку с помощью кросс-валидации\n",
    "# Реализуем сначала самую простую оценку\n",
    "\n",
    "accuracy_list = cross_val_score(logistic_model, X_Count, labelled_y, cv=5)   # Возвращает список score (в нашем случае это accuracy)\n",
    "print('Accuracy list: {}'.format(accuracy_list))\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 | Accuracy: 0.7962 | Precision: 0.7962 | Recall: 0.7962 | F1-score: 0.7962 \n",
      "Iteration #2 | Accuracy: 0.8187 | Precision: 0.8187 | Recall: 0.8187 | F1-score: 0.8187 \n",
      "Iteration #3 | Accuracy: 0.8305 | Precision: 0.8305 | Recall: 0.8305 | F1-score: 0.8305 \n",
      "Iteration #4 | Accuracy: 0.7465 | Precision: 0.7465 | Recall: 0.7465 | F1-score: 0.7465 \n",
      "Iteration #5 | Accuracy: 0.8028 | Precision: 0.8028 | Recall: 0.8028 | F1-score: 0.8028 \n",
      "Mean of accuracy list: 0.7990 (+/- 0.0288)\n",
      "Mean of precision list: 0.7990 (+/- 0.0288)\n",
      "Mean of recall list: 0.7990 (+/- 0.0288)\n",
      "Mean of f1 score list: 0.7990 (+/- 0.0288)\n"
     ]
    }
   ],
   "source": [
    "# Теперь реализуем посредством того, что мы сами будем разбивать\n",
    "kf = KFold(n_splits=5)\n",
    "iter_number = 0\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_measure_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_Count):\n",
    "    iter_number += 1\n",
    "    X_train, X_test = X_Count[train_index], X_Count[test_index]\n",
    "    y_train, y_test = labelled_y[train_index], labelled_y[test_index]\n",
    "    \n",
    "    logistic_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "    predicted = logistic_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "\n",
    "    # Указываем micro\\macro, поскольку у нас три класса, т.е. мультиклассовая классификация\n",
    "    \n",
    "    print('Iteration #{} | Accuracy: {:0.4f} | Precision: {:0.4f} | Recall: {:0.4f} | F1-score: {:0.4f} '.format(\n",
    "        iter_number,\n",
    "        accuracy_score(predicted, y_test),\n",
    "        precision_score(predicted, y_test, average = 'micro'),\n",
    "        recall_score(predicted, y_test, average = 'micro'),\n",
    "        f1_score(predicted, y_test, average = 'micro')\n",
    "    ))\n",
    "    accuracy_list.append(accuracy_score(predicted, y_test))\n",
    "    precision_list.append(precision_score(predicted, y_test, average = 'micro'))\n",
    "    recall_list.append(recall_score(predicted, y_test, average = 'micro'))\n",
    "    f1_measure_list.append(f1_score(predicted, y_test, average = 'micro'))\n",
    "\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))\n",
    "print('Mean of precision list: {:.4f} (+/- {:.4f})'.format(np.mean(precision_list), np.std(precision_list)))\n",
    "print('Mean of recall list: {:.4f} (+/- {:.4f})'.format(np.mean(recall_list), np.std(recall_list)))\n",
    "print('Mean of f1 score list: {:.4f} (+/- {:.4f})'.format(np.mean(f1_measure_list), np.std(f1_measure_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение с ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labelled_y, test_size=0.2)\n",
    "\n",
    "\n",
    "vec = CountVectorizer(ngram_range = (1,2))\n",
    "\n",
    "clf = LogisticRegressionCV()   \n",
    "\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.61      0.71       735\n",
      "          1       0.80      0.93      0.86      1218\n",
      "\n",
      "avg / total       0.81      0.81      0.80      1953\n",
      "\n",
      "accuracy: 0.808\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        #target_names=twenty_test.target_names\n",
    "                                          )\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "df = eli5.explain_weights_df(clf, vec=vec,\n",
    "                 target_names=classEncoder.classes_\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('bayes_linregr_countvec_pred.txt', sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Репрезентация TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаем объект класса TF-IDF Vectorizer, который преобразует корпус текстов в TF-IDF\n",
    "TFIDFVectorizer = TfidfVectorizer(max_df=0.9, min_df=0.01, sublinear_tf=True)\n",
    "X_TF = TFIDFVectorizer.fit_transform(X)\n",
    "\n",
    "# Тогда разбить на тренировочную\\тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_TF, labelled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6575\n",
      "Precision: 0.6575\n",
      "Recall: 0.6575\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.26      0.38       773\n",
      "          1       0.65      0.92      0.76      1180\n",
      "\n",
      "avg / total       0.66      0.66      0.61      1953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_model = LinearSVC()  \n",
    "svm_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "predicted = svm_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(predicted, y_test)))\n",
    "print('Precision: {:0.4f}'.format(precision_score(predicted, y_test, average = 'micro')))\n",
    "print('Recall: {:0.4f}'.format(recall_score(predicted, y_test, average = 'micro')))\n",
    "\n",
    "print(classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy list: [0.6656426  0.67332309 0.6641065  0.65847414 0.66752049]\n",
      "Mean of accuracy list: 0.6658 (+/- 0.0048)\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = cross_val_score(svm_model, X_TF, labelled_y, cv=5)   \n",
    "print('Accuracy list: {}'.format(accuracy_list))\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 | Accuracy: 0.6489 | Precision: 0.6489 | Recall: 0.6489 | F1-score: 0.6489 \n",
      "Iteration #2 | Accuracy: 0.6981 | Precision: 0.6981 | Recall: 0.6981 | F1-score: 0.6981 \n",
      "Iteration #3 | Accuracy: 0.7124 | Precision: 0.7124 | Recall: 0.7124 | F1-score: 0.7124 \n",
      "Iteration #4 | Accuracy: 0.6888 | Precision: 0.6888 | Recall: 0.6888 | F1-score: 0.6888 \n",
      "Iteration #5 | Accuracy: 0.6998 | Precision: 0.6998 | Recall: 0.6998 | F1-score: 0.6998 \n",
      "Iteration #6 | Accuracy: 0.7059 | Precision: 0.7059 | Recall: 0.7059 | F1-score: 0.7059 \n",
      "Iteration #7 | Accuracy: 0.6977 | Precision: 0.6977 | Recall: 0.6977 | F1-score: 0.6977 \n",
      "Iteration #8 | Accuracy: 0.4119 | Precision: 0.4119 | Recall: 0.4119 | F1-score: 0.4119 \n",
      "Iteration #9 | Accuracy: 0.4744 | Precision: 0.4744 | Recall: 0.4744 | F1-score: 0.4744 \n",
      "Iteration #10 | Accuracy: 0.8504 | Precision: 0.8504 | Recall: 0.8504 | F1-score: 0.8504 \n",
      "Mean of accuracy list: 0.6588 (+/- 0.1194)\n",
      "Mean of precision list: 0.6588 (+/- 0.1194)\n",
      "Mean of recall list: 0.6588 (+/- 0.1194)\n",
      "Mean of f1 score list: 0.6588 (+/- 0.1194)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "iter_number = 0\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_measure_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_TF):\n",
    "    iter_number += 1\n",
    "    X_train, X_test = X_TF[train_index], X_TF[test_index]\n",
    "    y_train, y_test = labelled_y[train_index], labelled_y[test_index]\n",
    "    \n",
    "    svm_model.fit(X_train, y_train)                     \n",
    "    predicted = svm_model.predict(X_test)         \n",
    "\n",
    "    \n",
    "    \n",
    "    print('Iteration #{} | Accuracy: {:0.4f} | Precision: {:0.4f} | Recall: {:0.4f} | F1-score: {:0.4f} '.format(\n",
    "        iter_number,\n",
    "        accuracy_score(predicted, y_test),\n",
    "        precision_score(predicted, y_test, average = 'micro'),\n",
    "        recall_score(predicted, y_test, average = 'micro'),\n",
    "        f1_score(predicted, y_test, average = 'micro')\n",
    "    ))\n",
    "    accuracy_list.append(accuracy_score(predicted, y_test))\n",
    "    precision_list.append(precision_score(predicted, y_test, average = 'micro'))\n",
    "    recall_list.append(recall_score(predicted, y_test, average = 'micro'))\n",
    "    f1_measure_list.append(f1_score(predicted, y_test, average = 'micro'))\n",
    "\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))\n",
    "print('Mean of precision list: {:.4f} (+/- {:.4f})'.format(np.mean(precision_list), np.std(precision_list)))\n",
    "print('Mean of recall list: {:.4f} (+/- {:.4f})'.format(np.mean(recall_list), np.std(recall_list)))\n",
    "print('Mean of f1 score list: {:.4f} (+/- {:.4f})'.format(np.mean(f1_measure_list), np.std(f1_measure_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение с ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labelled_y, test_size=0.2)\n",
    "\n",
    "vec = TfidfVectorizer(max_df=0.9, min_df=0.01, sublinear_tf=True, ngram_range=(1,2))\n",
    "\n",
    "\n",
    "clf = LinearSVC()   \n",
    "\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.25      0.36       748\n",
      "          1       0.66      0.90      0.76      1205\n",
      "\n",
      "avg / total       0.64      0.65      0.61      1953\n",
      "\n",
      "accuracy: 0.653\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        #target_names=twenty_test.target_names\n",
    "                                          )\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = eli5.explain_weights_df(clf, vec=vec,\n",
    "                 target_names=classEncoder.classes_\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('bayes_svm_tfidf_pred.txt', sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Репрезентация с помощью CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Создаем объект класса CountVectorizer, который преобразует корпус текстов в one-hot представление\n",
    "CVectorizer = CountVectorizer()\n",
    "X_Count = CVectorizer.fit_transform(X)\n",
    "\n",
    "# Тогда разбить на тренировочную\\тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Count, labelled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8008\n",
      "Precision: 0.8008\n",
      "Recall: 0.8008\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.63      0.70       711\n",
      "          1       0.81      0.90      0.85      1242\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_model = LinearSVC()  \n",
    "svm_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "predicted = svm_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(predicted, y_test)))\n",
    "print('Precision: {:0.4f}'.format(precision_score(predicted, y_test, average = 'micro')))\n",
    "print('Recall: {:0.4f}'.format(recall_score(predicted, y_test, average = 'micro')))\n",
    "\n",
    "print(classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy list: [0.7921147  0.80286738 0.80337942 0.7921147  0.79661885]\n",
      "Mean of accuracy list: 0.7974 (+/- 0.0049)\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = cross_val_score(svm_model, X_Count, labelled_y, cv=5)   \n",
    "print('Accuracy list: {}'.format(accuracy_list))\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 | Accuracy: 0.7769 | Precision: 0.7769 | Recall: 0.7769 | F1-score: 0.7769 \n",
      "Iteration #2 | Accuracy: 0.8137 | Precision: 0.8137 | Recall: 0.8137 | F1-score: 0.8137 \n",
      "Iteration #3 | Accuracy: 0.8332 | Precision: 0.8332 | Recall: 0.8332 | F1-score: 0.8332 \n",
      "Iteration #4 | Accuracy: 0.8147 | Precision: 0.8147 | Recall: 0.8147 | F1-score: 0.8147 \n",
      "Iteration #5 | Accuracy: 0.8135 | Precision: 0.8135 | Recall: 0.8135 | F1-score: 0.8135 \n",
      "Iteration #6 | Accuracy: 0.8391 | Precision: 0.8391 | Recall: 0.8391 | F1-score: 0.8391 \n",
      "Iteration #7 | Accuracy: 0.8186 | Precision: 0.8186 | Recall: 0.8186 | F1-score: 0.8186 \n",
      "Iteration #8 | Accuracy: 0.6988 | Precision: 0.6988 | Recall: 0.6988 | F1-score: 0.6988 \n",
      "Iteration #9 | Accuracy: 0.7162 | Precision: 0.7162 | Recall: 0.7162 | F1-score: 0.7162 \n",
      "Iteration #10 | Accuracy: 0.8914 | Precision: 0.8914 | Recall: 0.8914 | F1-score: 0.8914 \n",
      "Mean of accuracy list: 0.8016 (+/- 0.0545)\n",
      "Mean of precision list: 0.8016 (+/- 0.0545)\n",
      "Mean of recall list: 0.8016 (+/- 0.0545)\n",
      "Mean of f1 score list: 0.8016 (+/- 0.0545)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "iter_number = 0\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_measure_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_Count):\n",
    "    iter_number += 1\n",
    "    X_train, X_test = X_Count[train_index], X_Count[test_index]\n",
    "    y_train, y_test = labelled_y[train_index], labelled_y[test_index]\n",
    "    \n",
    "    svm_model.fit(X_train, y_train)                     \n",
    "    predicted = svm_model.predict(X_test)         \n",
    "\n",
    "    \n",
    "    \n",
    "    print('Iteration #{} | Accuracy: {:0.4f} | Precision: {:0.4f} | Recall: {:0.4f} | F1-score: {:0.4f} '.format(\n",
    "        iter_number,\n",
    "        accuracy_score(predicted, y_test),\n",
    "        precision_score(predicted, y_test, average = 'micro'),\n",
    "        recall_score(predicted, y_test, average = 'micro'),\n",
    "        f1_score(predicted, y_test, average = 'micro')\n",
    "    ))\n",
    "    accuracy_list.append(accuracy_score(predicted, y_test))\n",
    "    precision_list.append(precision_score(predicted, y_test, average = 'micro'))\n",
    "    recall_list.append(recall_score(predicted, y_test, average = 'micro'))\n",
    "    f1_measure_list.append(f1_score(predicted, y_test, average = 'micro'))\n",
    "\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))\n",
    "print('Mean of precision list: {:.4f} (+/- {:.4f})'.format(np.mean(precision_list), np.std(precision_list)))\n",
    "print('Mean of recall list: {:.4f} (+/- {:.4f})'.format(np.mean(recall_list), np.std(recall_list)))\n",
    "print('Mean of f1 score list: {:.4f} (+/- {:.4f})'.format(np.mean(f1_measure_list), np.std(f1_measure_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение с ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labelled_y, test_size=0.2)\n",
    "\n",
    "\n",
    "vec = CountVectorizer(ngram_range = (1,2))\n",
    "\n",
    "clf = LinearSVC()   \n",
    "\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.60      0.68       729\n",
      "          1       0.79      0.91      0.85      1224\n",
      "\n",
      "avg / total       0.80      0.80      0.79      1953\n",
      "\n",
      "accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        #target_names=twenty_test.target_names\n",
    "                                          )\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "df = eli5.explain_weights_df(clf, vec=vec,\n",
    "                 target_names=classEncoder.classes_\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('bayes_svm_countvec_pred.txt', sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Репрезентация TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаем объект класса TF-IDF Vectorizer, который преобразует корпус текстов в TF-IDF\n",
    "TFIDFVectorizer = TfidfVectorizer(max_df=0.9, min_df=0.01, sublinear_tf=True)\n",
    "X_TF = TFIDFVectorizer.fit_transform(X)\n",
    "\n",
    "# Тогда разбить на тренировочную\\тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_TF, labelled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6723\n",
      "Precision: 0.6723\n",
      "Recall: 0.6723\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.24      0.35       725\n",
      "          1       0.67      0.93      0.78      1228\n",
      "\n",
      "avg / total       0.67      0.67      0.62      1953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multnb_model = MultinomialNB()  \n",
    "multnb_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "predicted = multnb_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "\n",
    "# Указываем micro\\macro, поскольку у нас три класса, т.е. мультиклассовая классификация\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(predicted, y_test)))\n",
    "print('Precision: {:0.4f}'.format(precision_score(predicted, y_test, average = 'micro')))\n",
    "print('Recall: {:0.4f}'.format(recall_score(predicted, y_test, average = 'micro')))\n",
    "\n",
    "print(classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy list: [0.65847414 0.67127496 0.67178699 0.65540195 0.67059426]\n",
      "Mean of accuracy list: 0.6655 (+/- 0.0071)\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = cross_val_score(multnb_model, X_TF, labelled_y, cv=5)   \n",
    "print('Accuracy list: {}'.format(accuracy_list))\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 | Accuracy: 0.6479 | Precision: 0.6479 | Recall: 0.6479 | F1-score: 0.6479 \n",
      "Iteration #2 | Accuracy: 0.6970 | Precision: 0.6970 | Recall: 0.6970 | F1-score: 0.6970 \n",
      "Iteration #3 | Accuracy: 0.7236 | Precision: 0.7236 | Recall: 0.7236 | F1-score: 0.7236 \n",
      "Iteration #4 | Accuracy: 0.6899 | Precision: 0.6899 | Recall: 0.6899 | F1-score: 0.6899 \n",
      "Iteration #5 | Accuracy: 0.7111 | Precision: 0.7111 | Recall: 0.7111 | F1-score: 0.7111 \n",
      "Iteration #6 | Accuracy: 0.7141 | Precision: 0.7141 | Recall: 0.7141 | F1-score: 0.7141 \n",
      "Iteration #7 | Accuracy: 0.6988 | Precision: 0.6988 | Recall: 0.6988 | F1-score: 0.6988 \n",
      "Iteration #8 | Accuracy: 0.3811 | Precision: 0.3811 | Recall: 0.3811 | F1-score: 0.3811 \n",
      "Iteration #9 | Accuracy: 0.4631 | Precision: 0.4631 | Recall: 0.4631 | F1-score: 0.4631 \n",
      "Iteration #10 | Accuracy: 0.8750 | Precision: 0.8750 | Recall: 0.8750 | F1-score: 0.8750 \n",
      "Mean of accuracy list: 0.6602 (+/- 0.1328)\n",
      "Mean of precision list: 0.6602 (+/- 0.1328)\n",
      "Mean of recall list: 0.6602 (+/- 0.1328)\n",
      "Mean of f1 score list: 0.6602 (+/- 0.1328)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "iter_number = 0\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_measure_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_TF):\n",
    "    iter_number += 1\n",
    "    X_train, X_test = X_TF[train_index], X_TF[test_index]\n",
    "    y_train, y_test = labelled_y[train_index], labelled_y[test_index]\n",
    "    \n",
    "    multnb_model.fit(X_train, y_train)                     \n",
    "    predicted = multnb_model.predict(X_test)         \n",
    "\n",
    "    \n",
    "    \n",
    "    print('Iteration #{} | Accuracy: {:0.4f} | Precision: {:0.4f} | Recall: {:0.4f} | F1-score: {:0.4f} '.format(\n",
    "        iter_number,\n",
    "        accuracy_score(predicted, y_test),\n",
    "        precision_score(predicted, y_test, average = 'micro'),\n",
    "        recall_score(predicted, y_test, average = 'micro'),\n",
    "        f1_score(predicted, y_test, average = 'micro')\n",
    "    ))\n",
    "    accuracy_list.append(accuracy_score(predicted, y_test))\n",
    "    precision_list.append(precision_score(predicted, y_test, average = 'micro'))\n",
    "    recall_list.append(recall_score(predicted, y_test, average = 'micro'))\n",
    "    f1_measure_list.append(f1_score(predicted, y_test, average = 'micro'))\n",
    "\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))\n",
    "print('Mean of precision list: {:.4f} (+/- {:.4f})'.format(np.mean(precision_list), np.std(precision_list)))\n",
    "print('Mean of recall list: {:.4f} (+/- {:.4f})'.format(np.mean(recall_list), np.std(recall_list)))\n",
    "print('Mean of f1 score list: {:.4f} (+/- {:.4f})'.format(np.mean(f1_measure_list), np.std(f1_measure_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение с ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labelled_y, test_size=0.2)\n",
    "\n",
    "vec = TfidfVectorizer(max_df=0.9, min_df=0.01, sublinear_tf=True, ngram_range=(1,3))\n",
    "\n",
    "\n",
    "clf = MultinomialNB()   \n",
    "\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.22      0.33       708\n",
      "          1       0.68      0.93      0.78      1245\n",
      "\n",
      "avg / total       0.66      0.67      0.62      1953\n",
      "\n",
      "accuracy: 0.670\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        #target_names=twenty_test.target_names\n",
    "                                          )\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = eli5.explain_weights_df(clf, vec=vec,\n",
    "                 target_names=classEncoder.classes_\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-cc1643696c99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bayes_multNB_tfidf_pred.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv('bayes_multNB_tfidf_pred.txt', sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Репрезентация с CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаем объект класса CountVectorizer, который преобразует корпус текстов в one-hot представление\n",
    "CVectorizer = CountVectorizer()\n",
    "X_Count = CVectorizer.fit_transform(X)\n",
    "\n",
    "# Тогда разбить на тренировочную\\тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Count, labelled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8228\n",
      "Precision: 0.8228\n",
      "Recall: 0.8228\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.67      0.73       719\n",
      "          1       0.82      0.91      0.87      1234\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multnb_model = MultinomialNB()  \n",
    "multnb_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "predicted = multnb_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "\n",
    "# Указываем micro\\macro, поскольку у нас три класса, т.е. мультиклассовая классификация\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(predicted, y_test)))\n",
    "print('Precision: {:0.4f}'.format(precision_score(predicted, y_test, average = 'micro')))\n",
    "print('Recall: {:0.4f}'.format(recall_score(predicted, y_test, average = 'micro')))\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy list: [0.80798771 0.8202765  0.81618024 0.82488479 0.81762295]\n",
      "Mean of accuracy list: 0.8174 (+/- 0.0056)\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = cross_val_score(multnb_model, X_Count, labelled_y, cv=5)   \n",
    "print('Accuracy list: {}'.format(accuracy_list))\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 | Accuracy: 0.8055 | Precision: 0.8055 | Recall: 0.8055 | F1-score: 0.8055 \n",
      "Iteration #2 | Accuracy: 0.8199 | Precision: 0.8199 | Recall: 0.8199 | F1-score: 0.8199 \n",
      "Iteration #3 | Accuracy: 0.8495 | Precision: 0.8495 | Recall: 0.8495 | F1-score: 0.8495 \n",
      "Iteration #4 | Accuracy: 0.8393 | Precision: 0.8393 | Recall: 0.8393 | F1-score: 0.8393 \n",
      "Iteration #5 | Accuracy: 0.8484 | Precision: 0.8484 | Recall: 0.8484 | F1-score: 0.8484 \n",
      "Iteration #6 | Accuracy: 0.8207 | Precision: 0.8207 | Recall: 0.8207 | F1-score: 0.8207 \n",
      "Iteration #7 | Accuracy: 0.8248 | Precision: 0.8248 | Recall: 0.8248 | F1-score: 0.8248 \n",
      "Iteration #8 | Accuracy: 0.7264 | Precision: 0.7264 | Recall: 0.7264 | F1-score: 0.7264 \n",
      "Iteration #9 | Accuracy: 0.7254 | Precision: 0.7254 | Recall: 0.7254 | F1-score: 0.7254 \n",
      "Iteration #10 | Accuracy: 0.9037 | Precision: 0.9037 | Recall: 0.9037 | F1-score: 0.9037 \n",
      "Mean of accuracy list: 0.8164 (+/- 0.0518)\n",
      "Mean of precision list: 0.8164 (+/- 0.0518)\n",
      "Mean of recall list: 0.8164 (+/- 0.0518)\n",
      "Mean of f1 score list: 0.8164 (+/- 0.0518)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "iter_number = 0\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_measure_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_Count):\n",
    "    iter_number += 1\n",
    "    X_train, X_test = X_Count[train_index], X_Count[test_index]\n",
    "    y_train, y_test = labelled_y[train_index], labelled_y[test_index]\n",
    "    \n",
    "    multnb_model.fit(X_train, y_train)                     \n",
    "    predicted = multnb_model.predict(X_test)         \n",
    "\n",
    "    \n",
    "    \n",
    "    print('Iteration #{} | Accuracy: {:0.4f} | Precision: {:0.4f} | Recall: {:0.4f} | F1-score: {:0.4f} '.format(\n",
    "        iter_number,\n",
    "        accuracy_score(predicted, y_test),\n",
    "        precision_score(predicted, y_test, average = 'micro'),\n",
    "        recall_score(predicted, y_test, average = 'micro'),\n",
    "        f1_score(predicted, y_test, average = 'micro')\n",
    "    ))\n",
    "    accuracy_list.append(accuracy_score(predicted, y_test))\n",
    "    precision_list.append(precision_score(predicted, y_test, average = 'micro'))\n",
    "    recall_list.append(recall_score(predicted, y_test, average = 'micro'))\n",
    "    f1_measure_list.append(f1_score(predicted, y_test, average = 'micro'))\n",
    "\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))\n",
    "print('Mean of precision list: {:.4f} (+/- {:.4f})'.format(np.mean(precision_list), np.std(precision_list)))\n",
    "print('Mean of recall list: {:.4f} (+/- {:.4f})'.format(np.mean(recall_list), np.std(recall_list)))\n",
    "print('Mean of f1 score list: {:.4f} (+/- {:.4f})'.format(np.mean(f1_measure_list), np.std(f1_measure_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение с ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labelled_y, test_size=0.2)\n",
    "\n",
    "\n",
    "vec = CountVectorizer(ngram_range = (1,3))\n",
    "\n",
    "clf = MultinomialNB()   \n",
    "\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.64      0.72       692\n",
      "          1       0.82      0.93      0.87      1261\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1953\n",
      "\n",
      "accuracy: 0.826\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        #target_names=twenty_test.target_names\n",
    "                                          )\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "df = eli5.explain_weights_df(clf, vec=vec,\n",
    "                 target_names=classEncoder.classes_\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-c055add3a1bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bayes_multNB_countvec_pred.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv('bayes_multNB_countvec_pred.txt', sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Репрезентация TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Создаем объект класса TF-IDF Vectorizer, который преобразует корпус текстов в TF-IDF\n",
    "TFIDFVectorizer = TfidfVectorizer(max_df=0.9, min_df=0.01, sublinear_tf=True)\n",
    "X_TF = TFIDFVectorizer.fit_transform(X)\n",
    "\n",
    "# Тогда разбить на тренировочную\\тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_TF, labelled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6318\n",
      "Precision: 0.6318\n",
      "Recall: 0.6318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.03      0.07       740\n",
      "          1       0.63      1.00      0.77      1213\n",
      "\n",
      "avg / total       0.72      0.63      0.50      1953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rand_model = RandomForestClassifier(n_estimators=1000, max_depth=4,\n",
    "                             random_state=2)  \n",
    "rand_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "predicted = rand_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "\n",
    "# Указываем micro\\macro, поскольку у нас три класса, т.е. мультиклассовая классификация\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(predicted, y_test)))\n",
    "print('Precision: {:0.4f}'.format(precision_score(predicted, y_test, average = 'micro')))\n",
    "print('Recall: {:0.4f}'.format(recall_score(predicted, y_test, average = 'micro')))\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy list: [0.63236047 0.63338454 0.63850486 0.6359447  0.63114754]\n",
      "Mean of accuracy list: 0.6343 (+/- 0.0026)\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = cross_val_score(rand_model, X_TF, labelled_y, cv=5)   \n",
    "print('Accuracy list: {}'.format(accuracy_list))\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 | Accuracy: 0.6182 | Precision: 0.6182 | Recall: 0.6182 | F1-score: 0.6182 \n",
      "Iteration #2 | Accuracy: 0.6673 | Precision: 0.6673 | Recall: 0.6673 | F1-score: 0.6673 \n",
      "Iteration #3 | Accuracy: 0.7032 | Precision: 0.7032 | Recall: 0.7032 | F1-score: 0.7032 \n",
      "Iteration #4 | Accuracy: 0.6714 | Precision: 0.6714 | Recall: 0.6714 | F1-score: 0.6714 \n",
      "Iteration #5 | Accuracy: 0.7008 | Precision: 0.7008 | Recall: 0.7008 | F1-score: 0.7008 \n",
      "Iteration #6 | Accuracy: 0.6906 | Precision: 0.6906 | Recall: 0.6906 | F1-score: 0.6906 \n",
      "Iteration #7 | Accuracy: 0.6855 | Precision: 0.6855 | Recall: 0.6855 | F1-score: 0.6855 \n",
      "Iteration #8 | Accuracy: 0.2910 | Precision: 0.2910 | Recall: 0.2910 | F1-score: 0.2910 \n",
      "Iteration #9 | Accuracy: 0.3801 | Precision: 0.3801 | Recall: 0.3801 | F1-score: 0.3801 \n",
      "Iteration #10 | Accuracy: 0.9221 | Precision: 0.9221 | Recall: 0.9221 | F1-score: 0.9221 \n",
      "Mean of accuracy list: 0.6330 (+/- 0.1682)\n",
      "Mean of precision list: 0.6330 (+/- 0.1682)\n",
      "Mean of recall list: 0.6330 (+/- 0.1682)\n",
      "Mean of f1 score list: 0.6330 (+/- 0.1682)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "iter_number = 0\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_measure_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_TF):\n",
    "    iter_number += 1\n",
    "    X_train, X_test = X_TF[train_index], X_TF[test_index]\n",
    "    y_train, y_test = labelled_y[train_index], labelled_y[test_index]\n",
    "    \n",
    "    rand_model.fit(X_train, y_train)                     \n",
    "    predicted = rand_model.predict(X_test)         \n",
    "\n",
    "    \n",
    "    \n",
    "    print('Iteration #{} | Accuracy: {:0.4f} | Precision: {:0.4f} | Recall: {:0.4f} | F1-score: {:0.4f} '.format(\n",
    "        iter_number,\n",
    "        accuracy_score(predicted, y_test),\n",
    "        precision_score(predicted, y_test, average = 'micro'),\n",
    "        recall_score(predicted, y_test, average = 'micro'),\n",
    "        f1_score(predicted, y_test, average = 'micro')\n",
    "    ))\n",
    "    accuracy_list.append(accuracy_score(predicted, y_test))\n",
    "    precision_list.append(precision_score(predicted, y_test, average = 'micro'))\n",
    "    recall_list.append(recall_score(predicted, y_test, average = 'micro'))\n",
    "    f1_measure_list.append(f1_score(predicted, y_test, average = 'micro'))\n",
    "\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))\n",
    "print('Mean of precision list: {:.4f} (+/- {:.4f})'.format(np.mean(precision_list), np.std(precision_list)))\n",
    "print('Mean of recall list: {:.4f} (+/- {:.4f})'.format(np.mean(recall_list), np.std(recall_list)))\n",
    "print('Mean of f1 score list: {:.4f} (+/- {:.4f})'.format(np.mean(f1_measure_list), np.std(f1_measure_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение с ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labelled_y, test_size=0.2)\n",
    "\n",
    "vec = TfidfVectorizer(max_df=0.9, min_df=0.01, sublinear_tf=True, ngram_range=(1,2))\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=4,\n",
    "                             random_state=2)   \n",
    "\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.02      0.04       732\n",
      "          1       0.63      1.00      0.77      1221\n",
      "\n",
      "avg / total       0.77      0.63      0.50      1953\n",
      "\n",
      "accuracy: 0.633\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        #target_names=twenty_test.target_names\n",
    "                                          )\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = eli5.explain_weights_df(clf, vec=vec,\n",
    "                 target_names=classEncoder.classes_\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('bayes_rand_tfidf_pred.txt', sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Репрезентация CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаем объект класса CountVectorizer, который преобразует корпус текстов в one-hot представление\n",
    "CVectorizer = CountVectorizer()\n",
    "X_Count = CVectorizer.fit_transform(X)\n",
    "\n",
    "# Тогда разбить на тренировочную\\тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Count, labelled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6272\n",
      "Precision: 0.6272\n",
      "Recall: 0.6272\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       728\n",
      "          1       0.63      1.00      0.77      1225\n",
      "\n",
      "avg / total       0.39      0.63      0.48      1953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dns\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rand_model = RandomForestClassifier(n_estimators=1000, max_depth=4,\n",
    "                             random_state=2)  \n",
    "rand_model.fit(X_train, y_train)                     # Обучаем на тренировочной выборке\n",
    "predicted = rand_model.predict(X_test)         # Тестируем на тестовой выборке\n",
    "\n",
    "# Указываем micro\\macro, поскольку у нас три класса, т.е. мультиклассовая классификация\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(predicted, y_test)))\n",
    "print('Precision: {:0.4f}'.format(precision_score(predicted, y_test, average = 'micro')))\n",
    "print('Recall: {:0.4f}'.format(recall_score(predicted, y_test, average = 'micro')))\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy list: [0.62570405 0.62570405 0.62570405 0.62570405 0.62602459]\n",
      "Mean of accuracy list: 0.6258 (+/- 0.0001)\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = cross_val_score(rand_model, X_Count, labelled_y, cv=5)   \n",
    "print('Accuracy list: {}'.format(accuracy_list))\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 | Accuracy: 0.6141 | Precision: 0.6141 | Recall: 0.6141 | F1-score: 0.6141 \n",
      "Iteration #2 | Accuracy: 0.6612 | Precision: 0.6612 | Recall: 0.6612 | F1-score: 0.6612 \n",
      "Iteration #3 | Accuracy: 0.6919 | Precision: 0.6919 | Recall: 0.6919 | F1-score: 0.6919 \n",
      "Iteration #4 | Accuracy: 0.6633 | Precision: 0.6633 | Recall: 0.6633 | F1-score: 0.6633 \n",
      "Iteration #5 | Accuracy: 0.6875 | Precision: 0.6875 | Recall: 0.6875 | F1-score: 0.6875 \n",
      "Iteration #6 | Accuracy: 0.6814 | Precision: 0.6814 | Recall: 0.6814 | F1-score: 0.6814 \n",
      "Iteration #7 | Accuracy: 0.6752 | Precision: 0.6752 | Recall: 0.6752 | F1-score: 0.6752 \n",
      "Iteration #8 | Accuracy: 0.2838 | Precision: 0.2838 | Recall: 0.2838 | F1-score: 0.2838 \n",
      "Iteration #9 | Accuracy: 0.3760 | Precision: 0.3760 | Recall: 0.3760 | F1-score: 0.3760 \n",
      "Iteration #10 | Accuracy: 0.9232 | Precision: 0.9232 | Recall: 0.9232 | F1-score: 0.9232 \n",
      "Mean of accuracy list: 0.6258 (+/- 0.1686)\n",
      "Mean of precision list: 0.6258 (+/- 0.1686)\n",
      "Mean of recall list: 0.6258 (+/- 0.1686)\n",
      "Mean of f1 score list: 0.6258 (+/- 0.1686)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "iter_number = 0\n",
    "\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_measure_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_Count):\n",
    "    iter_number += 1\n",
    "    X_train, X_test = X_Count[train_index], X_Count[test_index]\n",
    "    y_train, y_test = labelled_y[train_index], labelled_y[test_index]\n",
    "    \n",
    "    rand_model.fit(X_train, y_train)                     \n",
    "    predicted = rand_model.predict(X_test)         \n",
    "\n",
    "    \n",
    "    \n",
    "    print('Iteration #{} | Accuracy: {:0.4f} | Precision: {:0.4f} | Recall: {:0.4f} | F1-score: {:0.4f} '.format(\n",
    "        iter_number,\n",
    "        accuracy_score(predicted, y_test),\n",
    "        precision_score(predicted, y_test, average = 'micro'),\n",
    "        recall_score(predicted, y_test, average = 'micro'),\n",
    "        f1_score(predicted, y_test, average = 'micro')\n",
    "    ))\n",
    "    accuracy_list.append(accuracy_score(predicted, y_test))\n",
    "    precision_list.append(precision_score(predicted, y_test, average = 'micro'))\n",
    "    recall_list.append(recall_score(predicted, y_test, average = 'micro'))\n",
    "    f1_measure_list.append(f1_score(predicted, y_test, average = 'micro'))\n",
    "\n",
    "print('Mean of accuracy list: {:.4f} (+/- {:.4f})'.format(np.mean(accuracy_list), np.std(accuracy_list)))\n",
    "print('Mean of precision list: {:.4f} (+/- {:.4f})'.format(np.mean(precision_list), np.std(precision_list)))\n",
    "print('Mean of recall list: {:.4f} (+/- {:.4f})'.format(np.mean(recall_list), np.std(recall_list)))\n",
    "print('Mean of f1 score list: {:.4f} (+/- {:.4f})'.format(np.mean(f1_measure_list), np.std(f1_measure_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение с ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labelled_y, test_size=0.2)\n",
    "\n",
    "\n",
    "vec = CountVectorizer(ngram_range = (1,2))\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=4,\n",
    "                             random_state=2) \n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       734\n",
      "          1       0.62      1.00      0.77      1219\n",
      "\n",
      "avg / total       0.39      0.62      0.48      1953\n",
      "\n",
      "accuracy: 0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dns\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,\n",
    "        #target_names=twenty_test.target_names\n",
    "                                          )\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = eli5.explain_weights_df(clf, vec=vec,\n",
    "                 target_names=classEncoder.classes_\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('bayes_rand_countvec_pred.txt', sep='\\t', encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
